{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os,json\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "min_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 31.77it/s]\n"
     ]
    }
   ],
   "source": [
    "db = pd.read_csv('../data/news/News_result.csv')\n",
    "chars = {}\n",
    "#chars = dict()\n",
    "for indexs, a in tqdm(db[0:2].iterrows()):\n",
    "    #print(a['content'])\n",
    "    for w in a['content']: # 纯文本，不用分词\n",
    "        chars[w] = chars.get(w,0) + 1\n",
    "    for w in a['title']: # 纯文本，不用分词\n",
    "        chars[w] = chars.get(w,0) + 1\n",
    "chars = {i:j for i,j in chars.items() if j >= min_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2char = {i+4:j for i,j in enumerate(chars)}\n",
    "char2id = {j:i for i,j in id2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2id(s, start_end=False):\n",
    "    # 文字转整数id\n",
    "    if start_end: # 补上<start>和<end>标记， ‘2’代表start, '3'end，‘1’生僻字\n",
    "        ids = [char2id.get(c, 1) for c in s[:maxlen-2]]\n",
    "        ids = [2] + ids + [3]\n",
    "    else: # 普通转化\n",
    "        ids = [char2id.get(c, 1) for c in s[:maxlen]]\n",
    "    return ids\n",
    "\n",
    "def id2str(ids):\n",
    "    # id转文字，找不到的用空字符代替\n",
    "    return ''.join([id2char.get(i, '') for i in ids])\n",
    "\n",
    "\n",
    "def padding(x):\n",
    "    # padding至batch内的最大长度\n",
    "    ml = max([len(i) for i in x])\n",
    "    return [i + [0] * (ml-len(i)) for i in x]\n",
    "\n",
    "\n",
    "def data_generator():\n",
    "    # 数据生成器\n",
    "    X,Y = [],[]\n",
    "    while True:\n",
    "        for a in db.find():\n",
    "            X.append(str2id(a['content']))\n",
    "            Y.append(str2id(a['title'], start_end=True))\n",
    "            if len(X) == batch_size:\n",
    "                X = np.array(padding(X))\n",
    "                Y = np.array(padding(Y))\n",
    "                yield [X,Y], None\n",
    "                X,Y = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(x_set): # 输出一个词表大小的向量，来标记该词是否在文章出现过\n",
    "    x, x_mask = x_set\n",
    "    x = K.cast(x, 'int32')\n",
    "    x = K.one_hot(x, len(chars)+4)\n",
    "    x = K.sum(x_mask * x, 1, keepdims=True)\n",
    "    x = K.cast(K.greater(x, 0.5), 'float32')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleShift(Layer):\n",
    "    \"\"\"缩放平移变换层（Scale and shift）\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ScaleShift, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        kernel_shape = (1,)*(len(input_shape)-1) + (input_shape[-1],)\n",
    "        self.log_scale = self.add_weight(name='log_scale',\n",
    "                                         shape=kernel_shape,\n",
    "                                         initializer='zeros')\n",
    "        self.shift = self.add_weight(name='shift',\n",
    "                                     shape=kernel_shape,\n",
    "                                     initializer='zeros')\n",
    "    def call(self, inputs):\n",
    "        x_outs = K.exp(self.log_scale) * inputs + self.shift\n",
    "        return x_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_size = 128\n",
    "x_in = Input(shape=(None,))\n",
    "y_in = Input(shape=(None,))\n",
    "x = x_in\n",
    "y = y_in\n",
    "x_mask = Lambda(lambda x: K.cast(K.greater(K.expand_dims(x, 2), 0), 'float32'))(x)\n",
    "y_mask = Lambda(lambda x: K.cast(K.greater(K.expand_dims(x, 2), 0), 'float32'))(y)\n",
    "\n",
    "x_one_hot = Lambda(to_one_hot)([x, x_mask])\n",
    "x_prior = ScaleShift()(x_one_hot) # 学习输出的先验分布（标题的字词很可能在文章出现过）\n",
    "\n",
    "embedding = Embedding(len(chars)+4, char_size)\n",
    "x = embedding(x)\n",
    "y = embedding(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder，双层双向LSTM\n",
    "x = Bidirectional(LSTM(int(char_size/2), return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(int(char_size/2), return_sequences=True))(x)\n",
    "\n",
    "# decoder，双层单向LSTM\n",
    "y = LSTM(char_size, return_sequences=True)(y)\n",
    "y = LSTM(char_size, return_sequences=True)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interact(Layer):\n",
    "    \"\"\"交互层，负责融合encoder和decoder的信息\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Interact, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        in_dim = input_shape[0][-1]\n",
    "        out_dim = input_shape[1][-1]\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(in_dim, out_dim),\n",
    "                                      initializer='glorot_normal')\n",
    "    def call(self, inputs):\n",
    "        q, v, v_mask = inputs\n",
    "        k = v\n",
    "        mv = K.max(v - (1. - v_mask) * 1e10, axis=1, keepdims=True) # maxpooling1d\n",
    "        mv = mv + K.zeros_like(q[:,:,:1]) # 将mv重复至“q的timesteps”份\n",
    "        # 下面几步只是实现了一个乘性attention\n",
    "        qw = K.dot(q, self.kernel)\n",
    "        a = K.batch_dot(qw, k, [2, 2]) / 10.\n",
    "        a -= (1. - K.permute_dimensions(v_mask, [0, 2, 1])) * 1e10\n",
    "        a = K.softmax(a)\n",
    "        o = K.batch_dot(a, v, [2, 1])\n",
    "        # 将各步结果拼接\n",
    "        return K.concatenate([o, q, mv], 2)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, input_shape[0][1],\n",
    "                input_shape[0][2]+input_shape[1][2]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = Interact()([y, x, x_mask])\n",
    "xy = Dense(512, activation='relu')(xy)\n",
    "xy = Dense(len(chars)+4)(xy)\n",
    "xy = Lambda(lambda x: (x[0]+x[1])/2)([xy, x_prior]) # 与先验结果平均\n",
    "xy = Activation('softmax')(xy)\n",
    "\n",
    "# 交叉熵作为loss，但mask掉padding部分\n",
    "cross_entropy = K.sparse_categorical_crossentropy(y_in[:, 1:], xy[:, :-1])\n",
    "loss = K.sum(cross_entropy * y_mask[:, 1:, 0]) / K.sum(y_mask[:, 1:, 0])\n",
    "\n",
    "model = Model([x_in, y_in], xy)\n",
    "model.add_loss(loss)\n",
    "model.compile(optimizer=Adam(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_title(s, topk=3):\n",
    "    \"\"\"beam search解码\n",
    "    每次只保留topk个最优候选结果；如果topk=1，那么就是贪心搜索\n",
    "    \"\"\"\n",
    "    xid = np.array([str2id(s)] * topk) # 输入转id\n",
    "    yid = np.array([[2]] * topk) # 解码均以<start>开通，这里<start>的id为2\n",
    "    scores = [0] * topk # 候选答案分数\n",
    "    for i in range(50): # 强制要求标题不超过50字\n",
    "        proba = model.predict([xid, yid])[:, i, 3:] # 直接忽略<padding>、<unk>、<start>\n",
    "        log_proba = np.log(proba + 1e-6) # 取对数，方便计算\n",
    "        arg_topk = log_proba.argsort(axis=1)[:,-topk:] # 每一项选出topk\n",
    "        _yid = [] # 暂存的候选目标序列\n",
    "        _scores = [] # 暂存的候选目标序列得分\n",
    "        if i == 0:\n",
    "            for j in range(topk):\n",
    "                _yid.append(list(yid[j]) + [arg_topk[0][j]+3])\n",
    "                _scores.append(scores[j] + log_proba[0][arg_topk[0][j]])\n",
    "        else:\n",
    "            for j in range(len(xid)):\n",
    "                for k in range(topk): # 遍历topk*topk的组合\n",
    "                    _yid.append(list(yid[j]) + [arg_topk[j][k]+3])\n",
    "                    _scores.append(scores[j] + log_proba[j][arg_topk[j][k]])\n",
    "            _arg_topk = np.argsort(_scores)[-topk:] # 从中选出新的topk\n",
    "            _yid = [_yid[k] for k in _arg_topk]\n",
    "            _scores = [_scores[k] for k in _arg_topk]\n",
    "        yid = []\n",
    "        scores = []\n",
    "        for k in range(len(xid)):\n",
    "            if _yid[k][-1] == 3: # 找到<end>就返回\n",
    "                return id2str(_yid[k])\n",
    "            else:\n",
    "                yid.append(_yid[k])\n",
    "                scores.append(_scores[k])\n",
    "        yid = np.array(yid)\n",
    "    # 如果50字都找不到<end>，直接返回\n",
    "    return id2str(yid[np.argmax(scores)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
